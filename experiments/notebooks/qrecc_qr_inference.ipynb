{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf8a114-37c6-457a-9e56-89b6aa0f3f23",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "cdf8a114-37c6-457a-9e56-89b6aa0f3f23",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "import pandas as pd\n",
    "from transformers import T5Model, T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import Adafactor\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31232c2e-7a47-4c22-8c4c-b8020157b9e8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "31232c2e-7a47-4c22-8c4c-b8020157b9e8",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-42640fba2ef1f790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/ujan/.cache/huggingface/datasets/csv/default-42640fba2ef1f790/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d93794b7194cb4b3e884576df422d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d632f124e7f244418d604d1e6fa0d57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/ujan/.cache/huggingface/datasets/csv/default-42640fba2ef1f790/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8a148bbf7f459d940639735778076b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DataClass:\n",
    "\n",
    "  def __init__(self, data_dir):\n",
    "    self.data_dir = data_dir\n",
    "\n",
    "  def data_csv(self, f, output):\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    rewrites = []\n",
    "\n",
    "    filepath = self.data_dir+f\n",
    "\n",
    "    with open(filepath) as fl:\n",
    "      data = json.load(fl)\n",
    "      \n",
    "      for d in data:\n",
    "        contexts.append(d['context'])\n",
    "        questions.append(d['question'])\n",
    "        rewrites.append(d['rewrite'])\n",
    "\n",
    "      data = {'context':contexts, 'question':questions, 'rewrite':rewrites}\n",
    "      df = pd.DataFrame(data)\n",
    "      df.to_csv(output, index=False)\n",
    "\n",
    "\n",
    "data = DataClass('/home/ujan/Documents/conv-qa/data/interim/')\n",
    "\n",
    "data.data_csv('qrecc_train.json', 'train.csv')\n",
    "data.data_csv('qrecc_test.json', 'test.csv')\n",
    "\n",
    "qrecc = load_dataset('csv', data_files={'train': 'train.csv', 'test': 'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32ae592-f148-47eb-b5b1-e45555401d78",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f32ae592-f148-47eb-b5b1-e45555401d78",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "max_length= 256\n",
    "batch_size = 8\n",
    "dim = 768 # change BERT hidden size to change\n",
    "\n",
    "pretrained_model = 't5-base'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21f65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained('home/ujan/Documents/conv-qa/models/pretrained_models/t5-v1_1-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f588eb2-1184-4a2e-b98d-7ed59be97ec0",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3f588eb2-1184-4a2e-b98d-7ed59be97ec0",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a2d522e2154323826c00ec27e9951a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2390d84986e74a2cb9d3894776c5005c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08527b8e63fe4a0eac995df6773f543a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2474 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee968c34313f4128867633ebc4ad6a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/669 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_dataset(batch):\n",
    "  contexts = tokenizer(batch['context'], batch['question'], padding='max_length', truncation='only_first', max_length=max_length, add_special_tokens=True)\n",
    "  rewrites = tokenizer(batch['rewrite'], padding='max_length', truncation=True, max_length=max_length, add_special_tokens=True)\n",
    "\n",
    "  batch['ctx_input_ids'] = contexts.input_ids\n",
    "  batch['rwrt_input_ids'] = rewrites.input_ids\n",
    " \n",
    "\n",
    "  batch['ctx_attention_mask'] = contexts.attention_mask\n",
    "  batch['rwrt_attention_mask'] = rewrites.attention_mask\n",
    "\n",
    "  return batch\n",
    "\n",
    "\n",
    "# removing examples with no context\n",
    "qrecc = qrecc.filter(lambda x: isinstance(x['context'], str) and isinstance(x['rewrite'], str))\n",
    "\n",
    "\n",
    "# tokenizing\n",
    "dataset = qrecc.map(\n",
    "    tokenize_dataset, \n",
    "    batch_size = batch_size,\n",
    "    batched=True,\n",
    "    remove_columns=['context', 'question', 'rewrite']\n",
    ")\n",
    "\n",
    "\n",
    "dataset.set_format(\n",
    "    type='torch', columns=['ctx_input_ids', 'rwrt_input_ids', 'ctx_attention_mask', 'rwrt_attention_mask'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00480d41-838b-444c-8dee-efa843db48ee",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "00480d41-838b-444c-8dee-efa843db48ee",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6de24a-b86a-4697-bd76-5dc360aff22e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "af6de24a-b86a-4697-bd76-5dc360aff22e",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def valid_loss():\n",
    "  \n",
    "  val_loss = 0\n",
    "  idx = 0\n",
    "\n",
    "  for batch in test_loader:\n",
    "\n",
    "    ctx_input = batch['ctx_input_ids'].to(device) # QR input\n",
    "    ctx_attention = batch['ctx_attention_mask'].to(device)\n",
    "\n",
    "    rwrt_input = batch['rwrt_input_ids'].to(device) \n",
    "    rwrt_input[rwrt_input == tokenizer.pad_token_id] = -100\n",
    "    rwrt_input = rwrt_input.to(device)\n",
    "\n",
    "    loss = model(input_ids=ctx_input, attention_mask=ctx_attention, labels=rwrt_input).loss\n",
    "    val_loss += loss.item()\n",
    "\n",
    "    del ctx_input, ctx_attention, rwrt_input, loss\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "  return val_loss/idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ddb10e4-40c1-4a61-a74a-e534dbdcc095",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5ddb10e4-40c1-4a61-a74a-e534dbdcc095",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 1 : 5.871161286881014\n",
      "Valid loss after epoch 1 : 2.5643757415993864\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28740/3943417798.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('/storage/qrecc/models/qr/qr_gen3.pth'))\n",
    "\n",
    "model.train()\n",
    "\n",
    "optim = optimizer = Adafactor(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=0.0,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  \n",
    "  epoch_loss = 0\n",
    "\n",
    "  for batch in train_loader:\n",
    "\n",
    "    ctx_input = batch['ctx_input_ids'].to(device) # QR input\n",
    "    ctx_attention = batch['ctx_attention_mask'].to(device)\n",
    "\n",
    "    rwrt_input = batch['rwrt_input_ids'].to(device) \n",
    "    rwrt_input[rwrt_input == tokenizer.pad_token_id] = -100 # tokens with indices set to -100 are ignored (masked)\n",
    "    rwrt_input = rwrt_input.to(device)\n",
    "\n",
    "    loss = model(input_ids=ctx_input, attention_mask=ctx_attention, labels=rwrt_input).loss\n",
    "    epoch_loss += loss.item() \n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "\n",
    "    del ctx_input, ctx_attention, rwrt_input, loss\n",
    "\n",
    "  print('Train loss after epoch {} : {}'.format(epoch+1, epoch_loss/len(train_loader)))\n",
    "  model.eval()\n",
    "  print('Valid loss after epoch {} : {}'.format(epoch+1, valid_loss()))\n",
    "  print('\\n')\n",
    "  model.train()\n",
    "  torch.save(model.state_dict(), '/home/ujan/Documents/'+str(epoch+1)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881605b-28b7-424b-8fc4-fa59aa13a9ed",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2881605b-28b7-424b-8fc4-fa59aa13a9ed",
     "kernelId": "d257ef2e-08e6-4eb1-ac8a-5a6a309bbe64",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
