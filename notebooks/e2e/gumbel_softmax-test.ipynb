{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f856ae",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "51b4f39f",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install ipywidgets\n",
    "#!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f0c31",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2017ca6d",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5436ac",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "e689a69d",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "import pandas as pd\n",
    "from transformers import T5Model, T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import Adafactor\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75f595",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "65fe3398",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Dataclass for preprocessing and creating train and test csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e7869",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "60c771ea",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Huggingface models and tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef79cb",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "6af7654a",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "max_length= 384\n",
    "batch_size = 2  # 4\n",
    "dim = 768 # change BERT hidden size to change\n",
    "\n",
    "pretrained_model = 't5-base'\n",
    "#pretrained_model = 'google/t5-v1_1-base'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model)\n",
    "qr_model = T5ForConditionalGeneration.from_pretrained(pretrained_model)\n",
    "rc_model = T5ForConditionalGeneration.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d1947",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "83d93885",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/storage/qrecc/processed')\n",
    "dataset.set_format(\n",
    "    type='torch', columns=['ctx_input_ids', 'rwrt_input_ids', 'psg_input_ids',\n",
    "                           'ans_input_ids', 'ctx_attention_mask', 'rwrt_attention_mask',\n",
    "                           'psg_attention_mask'],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad7e91",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "62f9c28c",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Train and test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cb5f7",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "5a16cf3a",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43cc335",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "64141405",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Forward function and function for rolling tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77732a2",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "0c952d85",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def roll_by_gather(mat, dim, shifts:torch.LongTensor):\n",
    "    # assumes 2D array\n",
    "    n_rows, n_cols = mat.shape\n",
    "    \n",
    "    if dim == 0:\n",
    "        #print(mat)\n",
    "        arange1 = torch.arange(n_rows).view((n_rows, 1)).repeat((1, n_cols)).to(device)\n",
    "        #print(arange1)\n",
    "        arange2 = (arange1 - shifts) % n_rows\n",
    "        #print(arange2)\n",
    "        return torch.gather(mat, 0, arange2)\n",
    "    elif dim == 1:\n",
    "        arange1 = torch.arange(n_cols).view((1,n_cols)).repeat((n_rows,1)).to(device)\n",
    "        #print(arange1)\n",
    "        arange2 = (arange1 - shifts) % n_cols\n",
    "        #print(arange2)\n",
    "        return torch.gather(mat, 1, arange2)\n",
    "\n",
    "\n",
    "def forward(batch):\n",
    "\n",
    "    # context + question input\n",
    "    ctx_input = batch['ctx_input_ids'].to(device) # QR input\n",
    "    ctx_attention = batch['ctx_attention_mask'].to(device)\n",
    "\n",
    "    # gold rewrite input for qr loss\n",
    "    rwrt_input = batch['rwrt_input_ids']\n",
    "    # # tokens with indices set to -100 are ignored (masked)\n",
    "    rwrt_input[rwrt_input == tokenizer.pad_token_id] = -100 \n",
    "    rwrt_input = rwrt_input.to(device)\n",
    "    rwrt_attention = batch['rwrt_attention_mask'].to(device)\n",
    "\n",
    "    # passage input\n",
    "    psg_input = batch['psg_input_ids'].to(device)\n",
    "    # need to add sep token at the begining\n",
    "    # roll by 1 and add column of 1s\n",
    "    psg_input = torch.roll(psg_input, 1, 1)\n",
    "    psg_input[:, 0] = 1\n",
    "\n",
    "    # answer input\n",
    "    ans_input = batch['ans_input_ids']\n",
    "    # # tokens with indices set to -100 are ignored (masked)\n",
    "    ans_input[ans_input == tokenizer.pad_token_id] = -100 \n",
    "    ans_input = ans_input.to(device)\n",
    "\n",
    "    # feed context+question input and rewrite label to qr model\n",
    "    qr_output = qr_model(input_ids=ctx_input, attention_mask=ctx_attention, labels=rwrt_input)\n",
    "\n",
    "    # logits to be sampled from\n",
    "    logits = qr_output.logits\n",
    "\n",
    "    # qr loss\n",
    "    qr_loss = qr_output.loss\n",
    "\n",
    "    # gumbel softmax on the logits\n",
    "    # slice upto actual vocabulary sizegumbel_softmax\n",
    "    gumbel_output = F.gumbel_softmax(logits, tau=1, hard=True)[..., :act_vocab_size]\n",
    "    # print(gumbel_output.shape) # 2, 384, 32100\n",
    "    \n",
    "    norm_ycord = torch.linspace(-1, 1, act_vocab_size).to(device)\n",
    "    norm_xcord = torch.linspace(-1, 1, dim).to(device)\n",
    "    \n",
    "    embeddings = rc_model.get_input_embeddings().weight[:act_vocab_size, :] # 32100, 768\n",
    "    embeddings = embeddings.view(1, 1, act_vocab_size, -1) # 1, 1, 32100, 768\n",
    "    \n",
    "    embeddings = embeddings.repeat(gumbel_output.shape[0], 1, 1, 1) # 2, 1, 32100, 768\n",
    "\n",
    "    for i in range(max_length):\n",
    "      gumbeli = gumbel_output[:, i, :]\n",
    "      gumbeli = gumbeli.view(gumbeli.shape[0], 1, -1)  # grid\n",
    "      \n",
    "      gumbeli = torch.mul(gumbeli, norm_ycord)\n",
    "      print(gumbeli.shape)\n",
    "        \n",
    "      break\n",
    "      \n",
    "\n",
    "    # use to one hot samples (straight through trick) to get vocab ids using dummy vocab\n",
    "    rc_input = gumbel_output@dummy_vocab\n",
    "    rc_input = rc_input.to(device)\n",
    "\n",
    "    del gumbel_output, qr_output, logits, ctx_input, ctx_attention, rwrt_input\n",
    "\n",
    "    # mask rc input ids with attention mask\n",
    "    rc_input = torch.mul(rc_input, rwrt_attention)\n",
    "    # flip the rewrite attention mask, replace 1s with 0s and vice versa\n",
    "    # now the 1s represent the 'free space' in the rc_input tensor to fit the passages\n",
    "    flipped_rwrt_mask = torch.fliplr(rwrt_attention)\n",
    "    flipped_mask = flipped_rwrt_mask.clone()\n",
    "    flipped_mask[flipped_rwrt_mask == 0] = 1\n",
    "    flipped_mask[flipped_rwrt_mask == 1] = 0\n",
    "    # mask passage to extract ids that can fit in the rc_input tensor\n",
    "    extr_psg = torch.mul(flipped_mask, psg_input)\n",
    "    # find the shifts for each row of extr_psg\n",
    "    # this is equal to the number of 1s in each row of rwrt_attention\n",
    "    # reshape to column vector as required by the custom gather function\n",
    "    shifts = (rwrt_attention==1).sum(dim=1).reshape(-1, 1) \n",
    "    # roll each row by the amount occupied by rc_input in that row\n",
    "    trunc_psg = roll_by_gather(extr_psg, 1, shifts)\n",
    "    # add to get rwrt + psg as rc_input\n",
    "    rc_input = torch.add(rc_input, trunc_psg)\n",
    "    # create attention mask\n",
    "    rc_attention = rc_input.clone()\n",
    "    rc_attention[rc_input != 0] = 1\n",
    "\n",
    "    del flipped_rwrt_mask, flipped_mask, extr_psg, shifts, trunc_psg, psg_input\n",
    "    \n",
    "    rc_loss = rc_model(input_ids=rc_input, attention_mask=rc_attention, labels=ans_input).loss\n",
    "\n",
    "    #del ans_input, rc_input, rc_attention\n",
    "\n",
    "    return qr_loss, rc_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ad1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "qr_model.to(device)\n",
    "#rc_model.to(device)\n",
    "\n",
    "# load finetuned models\n",
    "qr_model.load_state_dict(torch.load('/storage/qrecc/models/qr/qr_gen3.pth'))\n",
    "#rc_model.load_state_dict(torch.load('/storage/qrecc/models/rc/rc_gen3.pth'))\n",
    "\n",
    "qr_model.train()\n",
    "#rc_model.train()\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "# optimizer\n",
    "optim = optimizer = Adafactor(\n",
    "    #list(qr_model.parameters())+list(rc_model.parameters()),\n",
    "    qr_model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=0.0,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False\n",
    ")\n",
    "\n",
    "config = {\n",
    "  \"learning_rate\": 1e-5,\n",
    "  \"epochs\": 2,\n",
    "  \"batch_size\": 4,\n",
    "  \"weight_decay\": 0.0,\n",
    "  \"temperature\": 1\n",
    "}\n",
    "\n",
    "#wandb.init(project=\"e2e-gradients\", entity=\"suicune\", reinit=True, config=config)\n",
    "\n",
    "#wandb.watch(qr_model, log=\"all\", log_freq=100)\n",
    "\n",
    "# vocabulary size\n",
    "act_vocab_size = len(tokenizer.get_vocab())\n",
    "# dummy vocab to get vocab ids after gumbel softmax\n",
    "dummy_vocab = torch.arange(act_vocab_size).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b26b8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e52aaf6f-ef70-47c0-89d9-7acddccd0b85",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Validation and Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da401b1",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "c80b1be6",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def valid_loss():\n",
    "  \n",
    "  qr_epoch_loss = 0\n",
    "  rc_epoch_loss = 0\n",
    "  idx = 0\n",
    "\n",
    "  for batch in test_loader:\n",
    "\n",
    "    qr_loss, rc_loss = forward(batch)\n",
    "\n",
    "    qr_epoch_loss += qr_loss.item()\n",
    "    rc_epoch_loss += rc_loss.item()\n",
    "\n",
    "    #del ans_input, rc_input, rc_attention\n",
    "    del qr_loss, rc_loss \n",
    "\n",
    "    idx += 1\n",
    "\n",
    "  print('Valid loss : {}, {}'.format(qr_epoch_loss/idx, rc_epoch_loss/idx))\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "  qr_epoch_loss = 0\n",
    "  rc_epoch_loss = 0\n",
    "\n",
    "  idx = 1\n",
    "\n",
    "  for batch in train_loader:\n",
    "\n",
    "    qr_loss, rc_loss = forward(batch)\n",
    "    #total_loss = sum([qr_loss, rc_loss])\n",
    "    qr_epoch_loss += qr_loss.item()\n",
    "    rc_epoch_loss += rc_loss.item()\n",
    "\n",
    "    #total_loss.backward()\n",
    "    rc_loss.backward()\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "      print('epoch {}, batch {}'.format(epoch, idx))\n",
    "\n",
    "      #grad_dict = {}\n",
    "      for name, param in rc_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "          print(name, param.grad)\n",
    "\n",
    "      #wandb.log(grad_dict)\n",
    "\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    break\n",
    "  break\n",
    "      \n",
    "    #del ans_input, rc_input, rc_attention\n",
    "    #del qr_loss, rc_loss, total_loss\n",
    "\n",
    "\n",
    "    #idx += 1\n",
    "\n",
    "\n",
    "  print('Train loss : {}, {}'.format(qr_epoch_loss/len(train_loader), rc_epoch_loss/len(train_loader)))\n",
    "  qr_model.eval()\n",
    "  rc_model.eval()\n",
    "  valid_loss()\n",
    "  print('\\n')\n",
    "  qr_model.train()\n",
    "  rc_model.train()\n",
    "  torch.save(qr_model.state_dict(), '/storage/qrecc/models/e2e/qr'+str(epoch+3)+'.pth')\n",
    "  torch.save(rc_model.state_dict(), '/storage/gumbel_softmaxqrecc/models/e2e/rc'+str(epoch+3)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecad6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada0eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bfd4560",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f1f8b5dc",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62"
    }
   },
   "source": [
    "Train loss : 0.3970739206526509, 0.45609857336574516\n",
    "Valid loss : 0.4757325287272927, 0.5390424355815783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe691e4",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "e9d2ffdc-994a-494b-b886-dde0455b86c8",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
    "loaded_weights = torch.tensor(saved_weights)\n",
    "loaded_weights.requires_grad = True\n",
    "loaded_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7104fd",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "c27ca15f-6f2a-4eb0-9cf0-815bb34f29ae",
     "kernelId": "37a183ac-3369-4798-9691-900cd068ab62",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
