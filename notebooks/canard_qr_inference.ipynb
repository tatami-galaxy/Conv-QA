{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee098e64-783c-4b88-bad4-07d53857e493",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "ee098e64-783c-4b88-bad4-07d53857e493",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8a114-37c6-457a-9e56-89b6aa0f3f23",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "cdf8a114-37c6-457a-9e56-89b6aa0f3f23",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "import pandas as pd\n",
    "from transformers import T5Model, T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import Adafactor\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31232c2e-7a47-4c22-8c4c-b8020157b9e8",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "31232c2e-7a47-4c22-8c4c-b8020157b9e8",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DataClass:\n",
    "\n",
    "  def __init__(self, data_dir):\n",
    "    self.data_dir = data_dir\n",
    "\n",
    "  def data_csv(self, f, output):\n",
    "\n",
    "    contxtqs = []\n",
    "    rewrites = []\n",
    "\n",
    "    filepath = self.data_dir+f\n",
    "\n",
    "    with open(filepath) as fl:\n",
    "      data = json.load(fl)\n",
    "      \n",
    "      for d in data:\n",
    "        contxtq = d['context']+' '+d['question']  # concatenating context and contextual question\n",
    "        contxtqs.append(contxtq)\n",
    "        rewrites.append(d['rewrite'])\n",
    "\n",
    "      data = {'conv':contxtqs, 'rewrite':rewrites}\n",
    "      df = pd.DataFrame(data)\n",
    "      df.to_csv(output, index=False)\n",
    "\n",
    "\n",
    "data = DataClass('/storage/qrecc/')\n",
    "\n",
    "data.data_csv('qrecc_train.json', 'train.csv')\n",
    "data.data_csv('qrecc_test.json', 'test.csv')\n",
    "\n",
    "qrecc = load_dataset('csv', data_files={'train': 'train.csv', 'test': 'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ae592-f148-47eb-b5b1-e45555401d78",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "f32ae592-f148-47eb-b5b1-e45555401d78",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "max_length= 384\n",
    "batch_size = 4\n",
    "dim = 768 # change BERT hidden size to change\n",
    "weight_decay = 0.01\n",
    "\n",
    "pretrained_model = 't5-base'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f588eb2-1184-4a2e-b98d-7ed59be97ec0",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "3f588eb2-1184-4a2e-b98d-7ed59be97ec0",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_dataset(batch):\n",
    "  context = tokenizer(batch['conv'], padding='max_length', truncation=True, max_length=max_length)\n",
    "  rewrites = tokenizer(batch['rewrite'], padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "  batch['ctx_input_ids'] = context.input_ids\n",
    "  batch['rwrt_input_ids'] = rewrites.input_ids\n",
    " \n",
    "\n",
    "  batch['ctx_attention_mask'] = context.attention_mask\n",
    "  batch['rwrt_attention_mask'] = rewrites.attention_mask\n",
    "\n",
    "  return batch\n",
    "\n",
    "\n",
    "# removing examples with no context\n",
    "qrecc = qrecc.filter(lambda x: isinstance(x['conv'], str) and isinstance(x['rewrite'], str))\n",
    "\n",
    "# removing examples with context length > 384\n",
    "qrecc = qrecc.filter(lambda x: len(tokenizer(x['conv']).input_ids) <= max_length)\n",
    "\n",
    "\n",
    "# tokenizing\n",
    "dataset = qrecc.map(\n",
    "    tokenize_dataset, \n",
    "    batch_size = batch_size,\n",
    "    batched=True,\n",
    "    remove_columns=['conv', 'rewrite']\n",
    ")\n",
    "\n",
    "\n",
    "dataset.set_format(\n",
    "    type='torch', columns=['ctx_input_ids', 'rwrt_input_ids', 'ctx_attention_mask', 'rwrt_attention_mask'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00480d41-838b-444c-8dee-efa843db48ee",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "00480d41-838b-444c-8dee-efa843db48ee",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6de24a-b86a-4697-bd76-5dc360aff22e",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "af6de24a-b86a-4697-bd76-5dc360aff22e",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def valid_loss():\n",
    "  \n",
    "  val_loss = 0\n",
    "  idx = 0\n",
    "\n",
    "  for batch in test_loader:\n",
    "\n",
    "    ctx_input = batch['ctx_input_ids'].to(device) # QR input\n",
    "    ctx_attention = batch['ctx_attention_mask'].to(device)\n",
    "\n",
    "    rwrt_input = batch['rwrt_input_ids'].to(device) \n",
    "    rwrt_input[rwrt_input == tokenizer.pad_token_id] = -100\n",
    "    rwrt_input = rwrt_input.to(device)\n",
    "\n",
    "    loss = model(input_ids=ctx_input, attention_mask=ctx_attention, labels=rwrt_input).loss\n",
    "    val_loss += loss.item()\n",
    "\n",
    "    del ctx_input, ctx_attention, rwrt_input, loss\n",
    "\n",
    "    idx += 1\n",
    "\n",
    "  return val_loss/idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb10e4-40c1-4a61-a74a-e534dbdcc095",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "5ddb10e4-40c1-4a61-a74a-e534dbdcc095",
     "kernelId": "",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "#ctx_encoder.load_state_dict(torch.load('/content/ctx_encoder5.pth'))\n",
    "\n",
    "model.train()\n",
    "\n",
    "optim = optimizer = Adafactor(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=0.0,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False\n",
    ")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  \n",
    "  epoch_loss = 0\n",
    "\n",
    "  for batch in train_loader:\n",
    "\n",
    "    ctx_input = batch['ctx_input_ids'].to(device) # QR input\n",
    "    ctx_attention = batch['ctx_attention_mask'].to(device)\n",
    "\n",
    "    rwrt_input = batch['rwrt_input_ids'].to(device) \n",
    "    rwrt_input[rwrt_input[:, :] == tokenizer.pad_token_id] = -100 # tokens with indices set to -100 are ignored (masked)\n",
    "    rwrt_input = rwrt_input.to(device)\n",
    "\n",
    "    loss = model(input_ids=ctx_input, attention_mask=ctx_attention, labels=rwrt_input).loss\n",
    "    epoch_loss += loss.item() \n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "\n",
    "    del ctx_input, ctx_attention, rwrt_input, loss\n",
    "\n",
    "  print('Train loss after epoch {} : {}'.format(epoch+1, epoch_loss/len(train_loader)))\n",
    "  model.eval()\n",
    "  print('Valid loss after epoch {} : {}'.format(epoch+1, valid_loss()))\n",
    "  print('\\n')\n",
    "  model.train()\n",
    "  torch.save(model.state_dict(), 'qr_gen'+str(epoch+1)+'.pth')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
