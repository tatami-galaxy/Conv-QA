{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a84e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from typing import List\n",
    "from datasets import load_dataset, load_metric, load_from_disk\n",
    "import pandas as pd\n",
    "from transformers import T5Model, T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import Adafactor\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf83285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s: str) -> str:\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "    return re.sub(regex, ' ', text)\n",
    "\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length= 384\n",
    "pretrained_model = 't5-base'\n",
    "device = torch.device('cuda')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_model)\n",
    "para_model = T5ForConditionalGeneration.from_pretrained(pretrained_model)\n",
    "rc_model = T5ForConditionalGeneration.from_pretrained(pretrained_model)\n",
    "\n",
    "#para_model.load_state_dict(torch.load('/home/ujan/Documents/conv-qa/models/finetuned_weights/rc_gen5.pth'))\n",
    "#rc_model.load_state_dict(torch.load('/home/ujan/Documents/conv-qa/models/finetuned_weights/rc_gen5.pth'))\n",
    "para_model.to(device)\n",
    "rc_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e06475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass:\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def data_csv(self, f, output):\n",
    "\n",
    "        answers = []\n",
    "        rewrites = []\n",
    "        passages = []\n",
    "        labels = []\n",
    "\n",
    "        filepath = self.data_dir+f\n",
    "\n",
    "        with open(filepath) as fl:\n",
    "            data = json.load(fl)\n",
    "      \n",
    "        for d in data:\n",
    "            \n",
    "            para_loss = {}\n",
    "    \n",
    "            answers.append(d['answer'])\n",
    "            rewrites.append(d['rewrite'])\n",
    "            passages.append(d['passage'])\n",
    "            \n",
    "            \n",
    "            \n",
    "            passage = t5_tokenizer(d['rewrite'], d['passage'], padding=True, truncation='only_second',\n",
    "                           max_length=max_length, add_special_tokens=True, return_tensors=\"pt\")\n",
    "            answer = t5_tokenizer(d['answer'], padding=True, truncation='only_second',\n",
    "                                  max_length=max_length, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "            psg_input = passage.input_ids.to(device)\n",
    "            psg_attention = passage.attention_mask.to(device)\n",
    "            ans_input = answer.input_ids\n",
    "            ans_input[ans_input == t5_tokenizer.pad_token_id] = -100\n",
    "            ans_input = ans_input.to(device)\n",
    "\n",
    "            org_loss = rc_model(input_ids=psg_input, attention_mask=psg_attention, labels=ans_input).loss.item()\n",
    "            \n",
    "            \n",
    "            source = tokenizer(d['rewrite'], truncation=True, max_length=max_length,\n",
    "                                      add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "            input_ids = source.input_ids.to(device)\n",
    "            attention_mask = source.attention_mask.to(device)\n",
    "            \n",
    "            outputs = para_model.generate(\n",
    "            input_ids=input_ids, attention_mask=attention_masks,\n",
    "            max_length=384,\n",
    "            do_sample=True,\n",
    "            top_k=120, # 120\n",
    "            top_p=0.95,\n",
    "            early_stopping=True,\n",
    "            num_return_sequences=10)\n",
    "\n",
    "            for output in outputs:\n",
    "                line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "                passage = tokenizer(line, d['passage'], padding=True, truncation='only_second',\n",
    "                                   max_length=max_length, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "                psg_input = passage.input_ids.to(device)\n",
    "                psg_attention = passage.attention_mask.to(device)\n",
    "\n",
    "                loss = rc_model(input_ids=psg_input, attention_mask=psg_attention, labels=ans_input).loss.item()\n",
    "                para_loss[line] = loss\n",
    "\n",
    "            if any(p < org_loss for p in losses): labels.append(min(para_loss, key=para_loss.get))\n",
    "            else : labels.append(d['rewrite'])\n",
    "\n",
    "            \n",
    "\n",
    "        data = {'answer':answers, 'passage':passages, 'rewrite':rewrites, 'labels':labels}\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(output, index=False)\n",
    "\n",
    "\n",
    "data = DataClass('/home/ujan/Documents/conv-qa/data/interim/')\n",
    "\n",
    "data.data_csv('qrecc_train.json', 'train.csv')\n",
    "data.data_csv('qrecc_test.json', 'test.csv')\n",
    "\n",
    "qrecc_para = load_dataset('csv', data_files={'train': 'train.csv', 'test': 'test.csv'})\n",
    "\n",
    "qrecc_para.save_to_disk(\"/home/ujan/Desktop/qrecc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
